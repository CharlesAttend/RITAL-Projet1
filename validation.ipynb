{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from src.data import load_data_part1\n",
    "from src.postprocessing import windows_post\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locuteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data_part1(\n",
    "    path=\"./part1_speaker_recognition/data/raw/corpus.tache1.learn.utf8\",\n",
    ")\n",
    "X_valid, y_valid = load_data_part1(\n",
    "    path=\"./part1_speaker_recognition/data/raw/corpus.tache1.test.utf8\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., -1,  1,  1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.pyenv/versions/3.10.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "d = joblib.load(\"./part1_speaker_recognition/gridsearch/results/part1_hrscv_LinearSVC.pkl\")\n",
    "pipeline = d.best_estimator_\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_hat = pd.Series(pipeline.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.replace({-1: \"M\", 1:\"C\"}).to_csv('./part1_speaker_recognition/data/validation/validation_LinearSVC_noPost.csv', index=False, header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_post_simple = windows_post(y_hat, 3)\n",
    "y_hat_post_simple.replace({-1: \"M\", 1:\"C\"}).to_csv('./part1_speaker_recognition/data/validation/validation_LinearSVC_simplePost.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "y_hat_post_hard = windows_post(y_hat)\n",
    "for i in range(2, 4):\n",
    "    y_hat_post_hard = windows_post(y_hat_post_hard, i)\n",
    "y_hat_post_hard.replace({-1: \"M\", 1:\"C\"}).to_csv('./part1_speaker_recognition/data/validation/validation_LinearSVC_hardPost.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "y_hat_post_hard = windows_post(y_hat)\n",
    "for i in range(2, 5):\n",
    "    print(i)\n",
    "    y_hat_post_hard = windows_post(y_hat_post_hard, i)\n",
    "y_hat_post_hard.replace({-1: \"M\", 1:\"C\"}).to_csv('./part1_speaker_recognition/data/validation/validation_LinearSVC_hardPost4.csv', index=False, header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model opti sur la f1 de Mitterant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './part1_speaker_recognition/gridsearch/results/part1_hrscv_LogisticRegression_ncc.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m d \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m./part1_speaker_recognition/gridsearch/results/part1_hrscv_LogisticRegression_ncc.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m pipeline \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39mbest_estimator_\n\u001b[1;32m      3\u001b[0m pipeline\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './part1_speaker_recognition/gridsearch/results/part1_hrscv_LogisticRegression_ncc.pkl'"
     ]
    }
   ],
   "source": [
    "d = joblib.load(\"./part1_speaker_recognition/gridsearch/results/part1_hrscv_LogisticRegression_ncc.pkl\")\n",
    "pipeline = d.best_estimator_\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_hat = pd.Series(pipeline.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_post_hard = windows_post(y_hat)\n",
    "for i in range(2, 5):\n",
    "    y_hat_post_hard = windows_post(y_hat_post_hard, i)\n",
    "y_hat_post_hard.replace({-1: \"M\", 1:\"C\"}).to_csv('./part1_speaker_recognition/data/validation/validation_LogisticRegression_ncc_hardPost4.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
